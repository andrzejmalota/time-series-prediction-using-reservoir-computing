{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_function(parameters, datasets, n_samples=5):\n",
    "    \"\"\"\n",
    "    Test the ESN with specific parameters on NARMA-10\n",
    "    :param parameters: Dictionary with parameters values\n",
    "    :param datasets: The dataset for the evaluation\n",
    "    :param n_samples: How many samples to test the model ?\n",
    "    :return: A tuple (model, fitness value)\n",
    "    \"\"\"\n",
    "    # Batch size (how many sample processed at the same time?)\n",
    "    batch_size = 1\n",
    "\n",
    "    # Predicted/target plot length\n",
    "    plot_length = 200\n",
    "\n",
    "    # Use CUDA?\n",
    "    use_cuda = False\n",
    "    use_cuda = torch.cuda.is_available() if use_cuda else False\n",
    "\n",
    "    # Reservoir hyper-parameters\n",
    "    spectral_radius = parameters['spectral_radius']\n",
    "#     leaky_rate = parameters['leaky_rate']\n",
    "    input_dim = 1\n",
    "    reservoir_size = parameters['reservoir_size']\n",
    "    connectivity = parameters['connectivity']\n",
    "    ridge_param = parameters['ridge_param']\n",
    "    input_scaling = parameters['input_scaling']\n",
    "    bias_scaling = parameters['bias_scaling']\n",
    "\n",
    "    # Data loader\n",
    "    trainloader = DataLoader(datasets[0], batch_size=batch_size, shuffle=False)\n",
    "    testloader = DataLoader(datasets[1], batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Average NRMSE\n",
    "    NRMSE_average = 0.0\n",
    "\n",
    "    # For each samples\n",
    "    for n in range(n_samples):\n",
    "        # Internal matrix\n",
    "        w_generator = echotorch.utils.matrix_generation.NormalMatrixGenerator(\n",
    "            connectivity=connectivity,\n",
    "            spetral_radius=spectral_radius\n",
    "        )\n",
    "\n",
    "        # Input weights\n",
    "        win_generator = echotorch.utils.matrix_generation.NormalMatrixGenerator(\n",
    "            connectivity=connectivity,\n",
    "            scale=input_scaling,\n",
    "            apply_spectral_radius=False\n",
    "        )\n",
    "\n",
    "        # Bias vector\n",
    "        wbias_generator = echotorch.utils.matrix_generation.NormalMatrixGenerator(\n",
    "            connectivity=connectivity,\n",
    "            scale=bias_scaling,\n",
    "            apply_spectral_radius=False\n",
    "        )\n",
    "\n",
    "        # Create a Leaky-integrated ESN,\n",
    "        # with least-square training algo.\n",
    "        # esn = etrs.ESN(\n",
    "        esn = etrs.ESN(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=reservoir_size,\n",
    "            output_dim=1,\n",
    "            learning_algo='inv',\n",
    "            w_generator=w_generator,\n",
    "            win_generator=win_generator,\n",
    "            wbias_generator=wbias_generator,\n",
    "            ridge_param=ridge_param\n",
    "        )\n",
    "\n",
    "        # Transfer in the GPU if possible\n",
    "        if use_cuda:\n",
    "            esn.cuda()\n",
    "        # end if\n",
    "\n",
    "        # For each batch\n",
    "        for data in trainloader:\n",
    "            # Inputs and outputs\n",
    "            inputs, targets = data\n",
    "\n",
    "            # Transform data to Variables\n",
    "            inputs, targets = Variable(inputs), Variable(targets)\n",
    "            if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "            # ESN need inputs and targets\n",
    "            esn(inputs, targets)\n",
    "        # end for\n",
    "\n",
    "        # Now we finalize the training by\n",
    "        # computing the output matrix Wout.\n",
    "        esn.finalize()\n",
    "\n",
    "        # Get the first sample in test set,\n",
    "        # and transform it to Variable.\n",
    "        dataiter = iter(testloader)\n",
    "        test_u, test_y = dataiter.next()\n",
    "        test_u, test_y = Variable(test_u), Variable(test_y)\n",
    "        if use_cuda: test_u, test_y = test_u.cuda(), test_y.cuda()\n",
    "\n",
    "        # Make a prediction with our trained ESN\n",
    "        y_predicted = esn(test_u)\n",
    "\n",
    "        # Add to sum of NRMSE\n",
    "        NRMSE_average += echotorch.utils.nrmse(y_predicted.data, test_y.data)\n",
    "    # end for\n",
    "\n",
    "    # Print test MSE and NRMSE\n",
    "    return esn, NRMSE_average / n_samples\n",
    "# end evaluation_function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import echotorch.utils.optimization as optim\n",
    "import numpy as np\n",
    "import json\n",
    "from narma_evaluation import evaluation_function\n",
    "from utils import *\n",
    "\n",
    "def find_hyperparams(prediction_horizon, interval):\n",
    "    # Manual seed initialisation\n",
    "    np.random.seed(1)\n",
    "    torch.manual_seed(1)\n",
    "\n",
    "    # Get a random optimizer\n",
    "    random_optimizer = optim.optimizer_factory.get_optimizer('random', R=50)\n",
    "\n",
    "    # Parameters ranges\n",
    "    param_ranges = dict()\n",
    "    param_ranges['spectral_radius'] = np.arange(0.1, 1.1, 0.1)\n",
    "    # param_ranges['leaky_rate'] = np.arange(0.1, 1.1, 0.1)\n",
    "    param_ranges['reservoir_size'] = np.arange(50, 500, 50)\n",
    "    param_ranges['connectivity'] = np.arange(0.1, 1.0, 0.1)\n",
    "    param_ranges['ridge_param'] = np.logspace(-10, 2, base=10, num=10)\n",
    "    param_ranges['input_scaling'] = np.arange(0.1, 1.1, 0.1)\n",
    "    param_ranges['bias_scaling'] = np.arange(0.0, 1.1, 0.1)\n",
    "\n",
    "\n",
    "    # data parameters\n",
    "    window_size = 1\n",
    "#     prediction_horizon = 5\n",
    "\n",
    "    ds_builder = DatasetBuilder()\n",
    "    X_train, y_train, X_test, y_test = ds_builder.build_dataset_simple(prediction_horizon, interval, data_path='../data/input_data.csv', train_pct=0.8)\n",
    "\n",
    "    dataset_train = MyDataset(X_train, y_train)\n",
    "    dataset_test = MyDataset(X_test, y_test)\n",
    "\n",
    "    # Launch the optimization of hyper-parameters\n",
    "    _, best_param, best_NRMSE = random_optimizer.optimize(\n",
    "        evaluation_function,\n",
    "        param_ranges,\n",
    "        (dataset_train, dataset_test),\n",
    "        n_samples=5\n",
    "    )\n",
    "\n",
    "    # Show the result\n",
    "    print(f\"Best hyper-parameters found for interval {interval}: {best_param}\")\n",
    "    print(f\"Best NRMSE : {best_NRMSE}\")\n",
    "\n",
    "    for k, v in best_param.items():\n",
    "        best_param[k] = float(v)\n",
    "        \n",
    "    with open(f'hyperparams/hyperparams_esn_{interval}.json', 'w') as fp:\n",
    "        json.dump(best_param, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amalota/Documents/magisterka/ml/project/time-series-prediction-using-reservoir-computing/models/utils.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X, y = torch.tensor(X), torch.tensor(y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper-parameters found for interval 1min: {'spectral_radius': 0.30000000000000004, 'reservoir_size': 300, 'connectivity': 0.30000000000000004, 'ridge_param': 2.1544346900318823e-05, 'input_scaling': 0.2, 'bias_scaling': 1.0}\n",
      "Best NRMSE : 0.2634685919495313\n",
      "Best hyper-parameters found for interval 60min: {'spectral_radius': 0.5, 'reservoir_size': 200, 'connectivity': 0.4, 'ridge_param': 0.00046415888336127724, 'input_scaling': 0.1, 'bias_scaling': 0.5}\n",
      "Best NRMSE : 0.7020035128000529\n",
      "Best hyper-parameters found for interval daily: {'spectral_radius': 0.1, 'reservoir_size': 250, 'connectivity': 0.5, 'ridge_param': 2.1544346900318823e-05, 'input_scaling': 0.1, 'bias_scaling': 0.8}\n",
      "Best NRMSE : 0.6661524030108785\n"
     ]
    }
   ],
   "source": [
    "prediction_horizons = [5, 8, 7]\n",
    "interval = ['1min', '60min', 'daily']\n",
    "\n",
    "for prediction_horizon, interval in zip(prediction_horizons, interval):\n",
    "    find_hyperparams(prediction_horizon, interval)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
